{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# incom.py - A Toolbox for Calculating Linguistic Distances and Asymmetries between Related Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Levenshtein distance, word adaptiation surprisal, and conditional entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to compute Levenshtein distance and word adaptation surprisal for a given set of word pairs. It is meant as a template that can be easily modified and adapted for different language pairs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%run ../utils.py\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the **costs matrix file** for a given language pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = '../inputs/costs/RU_BG_costs.xlsx'\n",
    "costs_RUBG = read_cost_matrix(file=costs, pair='RU/BG') \n",
    "costs_BGRU = costs_RUBG.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_RUBG.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_BGRU.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the word pairs given in an **excel file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = '../inputs/wordlists/120_RU_BG.xlsx'\n",
    "df = read_data(file=word_list, sheets='Tabelle1', drop_duplicates=True, remove_whitespace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the **Levenshtein distance** for all wordpairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levensthein_BGRU = levenshtein_distance(df, foreign='BG', native='RU', costs=costs_BGRU)  # from the perspective of a RU native reader\n",
    "levensthein_RUBG = levenshtein_distance(df, foreign='RU', native='BG', costs=costs_RUBG)  # from the perspective of a BG native reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levensthein_BGRU.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levensthein_RUBG.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that Levenshtein distance is symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert levensthein_BGRU['LD'].all() == levensthein_RUBG['LD'].all()\n",
    "assert levensthein_BGRU['normalized LD'].all() == levensthein_RUBG['normalized LD'].all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the **character surprisals** and **probabilities** based on the alignments computed in the previous step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_BGRU, surprisals_BGRU = character_surprisals(levensthein_BGRU, foreign='BG', native='RU')\n",
    "probs_RUBG, surprisals_RUBG = character_surprisals(levensthein_RUBG, foreign='RU', native='BG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprisals_BGRU.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprisals_RUBG.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_BGRU.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_RUBG.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the **transformation entropy** for each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_entropy_BG = character_entropy(surprisals_BGRU, probs_BGRU)  # from the perspective of a RU native reader\n",
    "char_entropy_RU = character_entropy(surprisals_RUBG, probs_RUBG)  # from the perspective of a BG native reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_entropy_BG.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_entropy_RU.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute **full conditional entropies** between the language pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_RU_BG = full_conditional_entropy('RU', 'BG', levensthein_RUBG, surprisals_BGRU, probs_BGRU)\n",
    "H_BG_RU = full_conditional_entropy('BG', 'RU', levensthein_BGRU, surprisals_RUBG, probs_RUBG)\n",
    "print('H(RU|BG): ', H_RU_BG)\n",
    "print('H(BG|RU): ', H_BG_RU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the **word adaptation surprisal** based on the alignments and character surprisal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "was_BGRU = word_adaptation_surprisal(levensthein_BGRU, surprisals_BGRU, probs_BGRU)  # from the perspective of a RU native reader\n",
    "was_RUBG = word_adaptation_surprisal(levensthein_RUBG, surprisals_RUBG, probs_RUBG)  # from the perspective of a BG native reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "was_BGRU.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "was_RUBG.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Create a **modified version** of the surprisal matrix with zeros on the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_surprisals_BGRU = modify_character_surprisals(surprisals_BGRU, diag_value=0.0)\n",
    "mod_surprisals_RUBG = modify_character_surprisals(surprisals_RUBG, diag_value=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Write the (intermediate) results to disk. **This step is only needed if you want to further manually modify the surprisals.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines only if you want to edit the surprisals manually in Excel\n",
    "\n",
    "# output_path = '../outputs/results/RU_BG_120_results_tmp.xlsx'\n",
    "# store_results(output_path, 'BG', 'RU', was_BGRU, was_RUBG, char_entropy_BG, char_entropy_RU, surprisals_BGRU, surprisals_RUBG, mod_surprisals_BGRU, mod_surprisals_RUBG, probs_BGRU, probs_RUBG, costs_BGRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Modify the surprisals directly in the output file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Read the modified surprisals from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines only if you edited the surprisals manually in Excel\n",
    "\n",
    "# df = read_data(output_path, sheets=['BG-RU-mod-surprisals', 'RU-BG-mod-surprisals'], index_col=0)\n",
    "# mod_surprisals_BGRU = df['BG-RU-mod-surprisals']\n",
    "# mod_surprisals_RUBG = df['RU-BG-mod-surprisals']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recompute the **full conditional entropies** based on modified surprisals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_RU_BG = full_conditional_entropy('RU', 'BG', levensthein_RUBG, mod_surprisals_BGRU, probs_BGRU)\n",
    "H_BG_RU = full_conditional_entropy('BG', 'RU', levensthein_BGRU, mod_surprisals_RUBG, probs_RUBG)\n",
    "print('H(RU|BG): ', H_RU_BG)\n",
    "print('H(BG|RU): ', H_BG_RU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recompute the **word adaptation surprisals** based on modified surprisals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_was_BGRU = word_adaptation_surprisal(levensthein_BGRU, mod_surprisals_BGRU, probs_BGRU)  # from the perspective of a RU native reader\n",
    "mod_was_RUBG = word_adaptation_surprisal(levensthein_RUBG, mod_surprisals_RUBG, probs_RUBG)  # from the perspective of a BG native reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_was_BGRU.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_was_RUBG.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and add scores from human **intelligibility experiments**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelligibility_scores_BGRU = '../inputs/intelligibility/RU_native_BG_foreign_120_items.xlsx'\n",
    "intelligibility_scores_RU = read_data(intelligibility_scores_BGRU, sheets='Tabelle1', drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "was_BGRU = append_intelligibility_scores(was_BGRU, intelligibility_scores_RU)\n",
    "mod_was_BGRU = append_intelligibility_scores(mod_was_BGRU, intelligibility_scores_RU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summed intelligibility score: ', np.sum(was_BGRU['intelligibility scores']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "was_BGRU.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_was_BGRU.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelligibility_scores_RUBG = '../inputs/intelligibility/BG_native_RU_foreign_120_items.xlsx'\n",
    "intelligibility_scores_BG = read_data(intelligibility_scores_RUBG, sheets='Tabelle1', drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "was_RUBG = append_intelligibility_scores(was_RUBG, intelligibility_scores_BG)\n",
    "mod_was_RUBG = append_intelligibility_scores(mod_was_RUBG, intelligibility_scores_BG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summed intelligibility score: ', np.sum(was_RUBG['intelligibility scores']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "was_RUBG.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_was_RUBG.head(2)  # inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the final results to disk**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../outputs/results/RU_BG_120_results.xlsx'\n",
    "store_results(output_path, 'BG', 'RU', was_BGRU, was_RUBG, char_entropy_BG, char_entropy_RU, surprisals_BGRU, surprisals_RUBG, mod_surprisals_BGRU, mod_surprisals_RUBG, probs_BGRU, probs_RUBG, costs_BGRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../outputs/results/RU_BG_120_mod_results.xlsx'\n",
    "store_results(output_path, 'BG', 'RU', mod_was_BGRU, mod_was_RUBG, char_entropy_BG, char_entropy_RU, surprisals_BGRU, surprisals_RUBG, mod_surprisals_BGRU, mod_surprisals_RUBG, probs_BGRU, probs_RUBG, costs_BGRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute (multiple) linear regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input matrix (n_samples, n_features)\n",
    "for data in [was_BGRU, was_RUBG]:\n",
    "    X1 = np.asarray([data['normalized LD']]).reshape(-1, 1)\n",
    "    X2 = np.asarray([data['normalized WAS']]).reshape(-1, 1)\n",
    "    X3 = np.asarray([data['normalized LD'], data['normalized WAS']]).T\n",
    "    y = data['intelligibility scores'].values.reshape(-1, 1)\n",
    "    X = [(X1, 'intelligibility score ~ normalized LD'), (X2, 'intelligibility score ~ normalized WAS'), (X3, 'intelligibility score ~ normalized LD + normalized WAS')]\n",
    "    \n",
    "    for (x, desc) in X: # select both normalized LD and normalized WAS as predictors, if you want to see the regression using only one of the vars as predictor replace X3 by either X2 or X1\n",
    "        reg = LinearRegression(fit_intercept=True, normalize=True).fit(x, y)\n",
    "        r_squared = reg.score(x, y)\n",
    "        print(desc)\n",
    "        print(f'R squared: {r_squared}')\n",
    "        print(f'Coefficients: {reg.coef_[0]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "c4incomslav"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
